# ğŸ¤ Pipeline Vocal â€” Architecture Audio d'EXO

## Vue d'ensemble

Pipeline vocal complet : capture micro â†’ dÃ©tection voix â†’ transcription â†’ LLM â†’ synthÃ¨se â†’ playback.

**Status :** âœ… ImplÃ©mentÃ© et opÃ©rationnel

## Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microphone  â”‚  PyAudio (16kHz, mono, PCM16)
â”‚   (PyAudio)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VAD Adaptatif   â”‚  wake_word.py â€” calibration bruit ambiant
â”‚  (RMS energy)    â”‚  seuil dynamique = noise_floor Ã— multiplicateur
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ bytes (utterance complÃ¨te)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Faster-Whisper  â”‚  STT â€” modÃ¨le "base" (configurable)
â”‚  (beam_size=1)   â”‚  langue: FR, exÃ©cution dans executor thread
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ str (transcription)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Wake Word       â”‚  DÃ©tection "Exo" (13 variantes phonÃ©tiques)
â”‚  + Extraction    â”‚  Extraction commande aprÃ¨s wake word
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ str (commande)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BrainEngine     â”‚  GPT-4o-mini + RAG ChromaDB + Function Calling
â”‚  (GPT-4o-mini)   â”‚  max_tokens=80, contexte local (heure, mÃ©tÃ©o)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ str (rÃ©ponse)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kokoro TTS      â”‚  SynthÃ¨se locale 24kHz, voix ff_siwis
â”‚  (cascade)       â”‚  Fallback: Piper â†’ OpenAI â†’ Fish-Speech â†’ Coqui
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ bytes (WAV)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pygame mixer    â”‚  Playback synchrone, micro coupÃ© pendant rÃ©ponse
â”‚  (playback)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Composants

### 1. VAD â€” Voice Activity Detection (`src/audio/wake_word.py`)

DÃ©tection d'activitÃ© vocale par Ã©nergie RMS avec seuil adaptatif.

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| `VOICE_THRESHOLD` | 300 RMS | Seuil fixe (ajustÃ© par l'adaptatif) |
| `SILENCE_CHUNKS` | 8 (~0.5s) | Silence requis pour fin d'utterance |
| `MIN_UTTERANCE_SEC` | 0.5s | DurÃ©e minimum d'une utterance valide |
| `MIN_VOICE_CHUNKS` | 4 | Chunks vocaux minimum (filtre bruit) |
| `EXO_VAD_MULTIPLIER` | 2.5 | Multiplicateur bruit ambiant â†’ seuil |

**Calibration automatique :** Au dÃ©marrage, mesure 30 chunks de bruit ambiant (mÃ©diane RMS). Le seuil effectif = `noise_floor Ã— EXO_VAD_MULTIPLIER`, bornÃ© entre 50% et 150% du seuil fixe.

### 2. STT â€” Speech-to-Text (`src/core/listener.py`)

Faster-Whisper avec exÃ©cution dans un thread executor (non-bloquant).

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| `WHISPER_MODEL` | base | ModÃ¨le (tiny/base/small/medium/large) |
| `beam_size` | 1 | Recherche greedy (plus rapide) |
| `language` | fr | Langue forcÃ©e franÃ§ais |
| Compute | CPU, float32 | Compatible tous systÃ¨mes |

**Latence mesurÃ©e :** ~0.5-1.5s (modÃ¨le "base" sur CPU)

**Filtre hallucinations :** Les transcriptions parasites de Whisper sur le silence ("sous-titres", "amara.org", "merci d'avoir regardÃ©"...) sont automatiquement rejetÃ©es.

### 3. Wake Word (`src/audio/wake_word.py`)

DÃ©tection du mot "Exo" dans la transcription Whisper.

**Variantes reconnues :** exo, Ã©cho, echo, expo, ego, exc, exot, x.o, x o, exau, exeau, exos, exho

**Extraction commande :** "Exo, quelle heure est-il ?" â†’ "quelle heure est-il ?"

### 4. TTS â€” Text-to-Speech (`src/assistant/tts_client.py`)

Cascade de moteurs TTS par ordre de prioritÃ© :

| PrioritÃ© | Moteur | Type | Latence | QualitÃ© |
|----------|--------|------|---------|---------|
| 1 | **Kokoro** | Local | ~0.8s | Haute (quasi-humaine) |
| 2 | Piper | Local | ~0.3s | Bonne |
| 3 | OpenAI TTS-1 | API | ~1-2s | TrÃ¨s haute |
| 4 | Fish-Speech | API | Variable | Bonne |
| 5 | Coqui VITS | Local | ~2-3s | Moyenne |

### 5. Playback (`src/core/listener.py`)

- Pygame mixer initialisÃ© au sample rate du TTS actif (24kHz pour Kokoro)
- Micro coupÃ© pendant la rÃ©ponse (anti-Ã©cho)
- Buffer micro vidÃ© aprÃ¨s playback

## Latence End-to-End

| Ã‰tape | DurÃ©e typique |
|-------|---------------|
| Capture VAD | 0.5-1s (parole + 0.5s silence) |
| Whisper STT | 0.5-1.5s |
| Brain GPT-4o-mini | 0.5-1.5s |
| Kokoro TTS | ~0.8s |
| **Total** | **~2-4s** |

## Diagnostic

```bash
# Monitoring temps rÃ©el (niveaux micro, VAD, STT, wake word)
python examples/test_pipeline_monitor.py --rounds 5

# Test E2E complet avec rÃ©ponse vocale
python examples/test_e2e_vocal.py
```

## Configuration

```env
# STT
WHISPER_MODEL=base             # tiny|base|small|medium|large

# VAD
EXO_VAD_MULTIPLIER=2.5        # SensibilitÃ© (plus bas = plus sensible)

# TTS
TTS_ENGINE=kokoro              # kokoro|piper|openai|fish|coqui
KOKORO_VOICE=ff_siwis          # Voix franÃ§aise
KOKORO_LANG=f                  # f = franÃ§ais
```
