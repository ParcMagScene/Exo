# üé§ Voice Integration - Audio Realtime

## Vue d'ensemble

Int√©gration compl√®te du pipeline audio STT + LLM + TTS avec mesure de latence en temps r√©el.

**Status:** ‚úÖ **IMPL√âMENT√â ET TEST√â**

## Composants

### 1. Audio Capture Module (`src/audio/audio_capture.py`)
Module de capture audio en temps r√©el depuis le microphone avec PyAudio.

**Fonctionnalit√©s:**
- Capture audio PCM16 √† 16kHz (configurable)
- D√©tection et √©num√©ration des p√©riph√©riques audio
- Mode synchrone et asynchrone
- D√©tection automatique du silence
- Callbacks pour chaque frame
- Classe `AudioStats` pour analyser l'√©nergie (RMS)

**Classes:**
```python
class AudioCapture:
    - start_recording() / stop_recording()
    - capture_chunk() - lecture d'une chunk async
    - record_duration(seconds) - enregistrer X secondes
    - record_until_silence() - enregistrer jusqu'au silence
    - list_devices() - √©num√©rer les micros disponibles
```

**Usage:**
```python
capture = AudioCapture(sample_rate=16000, channels=1)
audio_bytes = await capture.record_duration(3.0)  # 3 secondes
```

### 2. Examples - Test Suite

#### a) `examples/test_latency.py`
Benchmark complet des composants STT, TTS et E2E.

**Mesure:**
- ‚úÖ STT (Faster-Whisper): latence transcription
- ‚úÖ TTS (Fish-Speech): latence synth√®se
- ‚úÖ E2E: latence totale pipeline

**Output:**
```
BENCHMARK STT (Faster-Whisper) - 2 runs
   Latence moyenne: XXX ms
   
BENCHMARK TTS (Fish-Speech) - 2 runs
   Latence moyenne: YYY ms
   
BENCHMARK E2E (STT + LLM + TTS)
   Total: ZZZ ms
   ‚úÖ Objectif <500ms: [ATTEINT/EXC√âD√â]
```

**Ex√©cution:**
```bash
python examples/test_latency.py
```

#### b) `examples/test_voice.py`
D√©mo interactive voice avec modes:

**Mode 1: Microphone R√©el (si PyAudio disponible)**
- Capture audio du micro (3 secondes ou jusqu'au silence)
- Conversion STT (audio ‚Üí texte)
- Traitement LLM (texte ‚Üí r√©ponse)
- Synth√®se TTS (r√©ponse ‚Üí audio)
- Affichage des latences d√©taill√©es

**Mode 2: Simulation Texte (sans micro)**
- Input texte simul√©
- Pipeline: STT (simul√© 100ms) ‚Üí LLM ‚Üí TTS (simul√© 200ms)
- Montre la mesure de latence E2E
- 2 sc√©narios de test (philo + domotique)

**Ex√©cution:**
```bash
python examples/test_voice.py
```

**Output exemple:**
```
üé§ MODE MICROPHONE R√âEL
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üìã P√©riph√©riques audio disponibles:
   Device 0: Mappeur de sons Microsoft - Input (2 channels, 44100Hz)
   Device 1: Speakerphone (Brio 500) (2 channels, 44100Hz)
   ...

üî¥ Enregistrement... (3 secondes)
‚úì Audio captur√© (90112 bytes)

[1/3] STT (audio ‚Üí texte)...
‚úì Transcription: 'bonjour comment allez vous'
  Latence: 250.45 ms

[2/3] LLM (texte ‚Üí r√©ponse)...
‚úì R√©ponse: 'Bonjour! Je vais bien, merci de...'
  Latence: 450.23 ms

[3/3] TTS (r√©ponse ‚Üí audio)...
‚úì Audio g√©n√©r√©e (48000 bytes)
  Latence: 320.10 ms

‚è±Ô∏è  LATENCE D√âTAILL√âE:
   üé§ STT:   250.45 ms
   üß† LLM:   450.23 ms
   üîä TTS:   320.10 ms
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   ‚åõ TOTAL: 1020.78 ms
   ‚ö†Ô∏è  Objectif <500ms: exc√©d√© de +520ms
```

### 3. Bug Fixes et Optimisations

**Config.py:**
- Rendu des validations optionnelles (via `SUPPRESS_CONFIG_WARNINGS`)
- Permet le lancement sans tous les secrets Azure/HA

**Brain Engine:**
- Corrig√© les f-strings multilignes avec caract√®res sp√©ciaux
- Ajout√© param√®tres `temperature` et `max_tokens` personnalisables

## Architecture Pipeline Audio

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Microphone   ‚îÇ
‚îÇ  (PyAudio)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ PCM16 @ 16kHz
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  AudioCapture    ‚îÇ
‚îÇ record_duration()‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ bytes (audio)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  HardwareAccelerator ‚îÇ
‚îÇ transcribe_audio()   ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ STT (Faster-Whisper + OpenVINO)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ str (text)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   BrainEngine       ‚îÇ
‚îÇ process_command()   ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ LLM (GPT-4o avec RAG)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ dict (response)
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ HardwareAccelerator  ‚îÇ
‚îÇ text_to_speech()     ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ TTS (Fish-Speech)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ bytes (audio)
       ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Output‚îÇ (speaker/file)
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Mesure de latence √† chaque √©tape:**

```python
async def full_pipeline():
    # 1. Capture
    stt_start = time.time()
    text = await hardware.transcribe_audio(audio)
    stt_latency_ms = (time.time() - stt_start) * 1000
    
    # 2. LLM
    llm_start = time.time()
    response = await brain.process_command(text)
    llm_latency_ms = (time.time() - llm_start) * 1000
    
    # 3. TTS
    tts_start = time.time()
    audio_out = await hardware.text_to_speech(response['text'])
    tts_latency_ms = (time.time() - tts_start) * 1000
    
    total_ms = stt_latency_ms + llm_latency_ms + tts_latency_ms
```

## D√©pendances

**Requises pour audio capture:**
```bash
pip install pyaudio
```

**Optionnelles pour STT/TTS optimis√©:**
```bash
pip install faster-whisper     # STT avec GPU/OpenVINO
pip install numpy              # Audio processing
pip install numba              # Acc√©l√©ration Whisper
```

**Pour Fish-Speech TTS:**
- D√©ployer Docker: `docker run -p 8000:8000 fish-speech` 
- Ou serveur HTTP √† `localhost:8000` (configurable en `.env`)

## Configuration

Ajouter √† `.env`:

```ini
# Audio Capture
AUDIO_SAMPLE_RATE=16000
AUDIO_CHANNELS=1
AUDIO_CHUNK_SIZE=1024

# STT
WHISPER_WORKERS=8        # Nombre de workers
DEVICE=auto              # cuda, cpu, auto

# TTS
FISH_SPEECH_ENDPOINT=http://localhost:8000
```

## Cas d'usage

### 1. Conversation vocale directe
```python
assistant = VoiceAssistant()
await assistant.run_interactive_demo()
```

### 2. Benchmark de latence
```bash
python examples/test_latency.py
# Mesure STT, TTS et E2E
```

### 3. Test de performances
```bash
python examples/test_performance.py
# Identifie les goulots d'√©tranglement
```

## Targets de Latence

**Objectif global:** <500ms E2E

**Breakdown indicatif** (i9-11900KF + GPU):
- STT (3s audio): ~150-250ms
- LLM (GPT-4o requ√™te): ~200-400ms  
- TTS (synth√®se): ~100-200ms
- **Total objectif:** ~500-900ms

## Int√©gration avec Wyoming Protocol

Pour multi-room audio avec Raspberry Pi:

```python
# Pi satellites envoient audio via Wyoming
wyoming_server = WyomingServer(host="0.0.0.0", port=10700)
await wyoming_server.start()

# Central server re√ßoit audio de plusieurs Pi
# Et utilise VoiceAssistant pour traitement
```

## √âtat Actuel

‚úÖ **Impl√©ment√©:**
- [x] AudioCapture module (PyAudio)
- [x] Test suite (latency benchmark)
- [x] Voice demo interactive
- [x] Mesure latence d√©taill√©e
- [x] Support microphone r√©el
- [x] Mode simulation (sans d√©pendances)
- [x] Config optionnelle

‚ö†Ô∏è **Optionnel (d√©pendances externes):**
- [ ] Faster-Whisper (pas install√© par d√©faut)
- [ ] Fish-Speech (service Docker)
- [ ] Azure OpenAI SDK (fallback REST disponible)

## Prochaines √©tapes

1. **Installer d√©pendances audio:**
   ```bash
   pip install pyaudio faster-whisper numpy
   ```

2. **Lancer Fish-Speech Docker:**
   ```bash
   docker run -p 8000:8000 fish-audio/fish-speech:latest
   ```

3. **Configurer `.env` avec Azure credentials**

4. **Tester la d√©mo compl√®te:**
   ```bash
   python examples/test_voice.py
   ```

5. **D√©ployer sur Raspberry Pi satellites avec Wyoming protocol**

## Am√©liorations futures

- [ ] WebRTC pour latence ultra-faible (<100ms)
- [ ] GPU optimization pour STT/TTS
- [ ] Streaming audio (ne pas attendre fin phrase)
- [ ] Multi-user queue gestion
- [ ] Voice activity detection (VAD) pour silence automatique
- [ ] Cache responses similaires pour latence r√©duite
- [ ] Support multiple languages
