"""wake_word.py - DÃ©tection du mot d'activation "EXO" + VAD.

Ã‰coute continue du microphone avec dÃ©tection d'activitÃ© vocale (VAD).
Quand une utterance est captÃ©e, elle est transcrite et analysÃ©e pour le wake word.

FonctionnalitÃ©s:
- VAD (Voice Activity Detection) par RMS energy avec seuil adaptatif
- Capture d'utterance complÃ¨te (voix â†’ silence = fin)
- DÃ©tection du mot "EXO" dans la transcription Whisper
- Extraction de la commande aprÃ¨s le wake word
"""

import asyncio
import logging
import os
import time
from typing import Optional
import numpy as np

logger = logging.getLogger(__name__)

# â”€â”€â”€ Wake word variants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Whisper peut transcrire "Exo" de plusieurs faÃ§ons selon l'accent
WAKE_WORDS = [
    "exo", "Ã©cho", "echo", "expo", "ego", "exc", "exot",
    "x.o", "x o", "exau", "exeau", "exos", "exho",
]

# â”€â”€â”€ VAD Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Seuils abaissÃ©s pour capter les voix douces et commandes courtes
DEFAULT_VOICE_THRESHOLD = 300       # RMS seuil pour "voix active" (abaissÃ© de 500)
DEFAULT_SILENCE_CHUNKS = 8         # ~0.5s de silence = fin d'utterance (rÃ©duit de 12)
DEFAULT_MIN_UTTERANCE_SEC = 0.5    # Ignorer bruits < 0.5s (rÃ©duit de 0.8)
DEFAULT_MAX_UTTERANCE_SEC = 15.0   # SÃ©curitÃ© max
DEFAULT_MIN_VOICE_CHUNKS = 4       # Au moins 4 chunks vocaux (rÃ©duit de 8)

# â”€â”€â”€ Seuil adaptatif â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ADAPTIVE_MULTIPLIER = float(os.environ.get("EXO_VAD_MULTIPLIER", "2.5"))
NOISE_FLOOR_SAMPLES = 30           # Nb chunks pour calibrer le bruit ambiant

# â”€â”€â”€ Hallucinations Whisper connues (filtrÃ©es) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WHISPER_HALLUCINATIONS = [
    "sous-titres", "sous-titre", "amara.org", "amara",
    "merci d'avoir regardÃ©", "merci de votre attention",
    "traduisez", "subscribe", "abonnez",
    "...", "â€¦", "â™ª", "ðŸŽµ",
]


def rms_energy(audio_bytes: bytes) -> float:
    """Calcule l'Ã©nergie RMS d'un buffer audio PCM16."""
    samples = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32)
    if len(samples) == 0:
        return 0.0
    return float(np.sqrt(np.mean(samples ** 2)))


def is_hallucination(text: str) -> bool:
    """DÃ©tecte les hallucinations connues de Whisper sur le silence."""
    text_lower = text.lower().strip()
    # Texte trop court ou que des points/espaces
    clean = text_lower.replace(".", "").replace(" ", "").replace("â€¦", "")
    if len(clean) < 3:
        return True
    for h in WHISPER_HALLUCINATIONS:
        if h in text_lower:
            return True
    return False


def contains_wake_word(text: str) -> bool:
    """VÃ©rifie si le texte contient le mot d'activation 'EXO'."""
    if is_hallucination(text):
        return False
    text_lower = text.lower().strip()
    for w in WAKE_WORDS:
        if w in text_lower:
            return True
    return False


def extract_command_after_wake(text: str) -> str:
    """Extrait la commande aprÃ¨s le mot d'activation.

    Exemples:
        "Exo, quelle heure est-il ?" â†’ "quelle heure est-il ?"
        "Exo allume la lumiÃ¨re"       â†’ "allume la lumiÃ¨re"
        "Exo"                         â†’ ""
    """
    text_clean = text.strip()
    text_lower = text_clean.lower()

    best_idx = -1
    best_len = 0
    for w in WAKE_WORDS:
        idx = text_lower.find(w)
        if idx >= 0 and (best_idx < 0 or len(w) > best_len):
            best_idx = idx
            best_len = len(w)

    if best_idx < 0:
        return text_clean

    after = text_clean[best_idx + best_len:]
    # Nettoyer ponctuation/espaces rÃ©siduels au dÃ©but
    after = after.lstrip(" ,.:;!?Â·\t\n")
    return after


# â”€â”€â”€ Noise floor adaptatif (partagÃ© entre appels) â”€â”€â”€â”€â”€â”€â”€â”€
_noise_floor: float = 0.0
_noise_calibrated: bool = False


def calibrate_noise_floor(stream, chunk_size: int = 1024, num_samples: int = NOISE_FLOOR_SAMPLES) -> float:
    """Mesure le bruit ambiant sur N chunks pour calibrer le seuil VAD.

    AppelÃ© au dÃ©marrage et pÃ©riodiquement pour s'adapter Ã  l'environnement.
    """
    global _noise_floor, _noise_calibrated
    energies = []
    for _ in range(num_samples):
        try:
            data = stream.read(chunk_size, exception_on_overflow=False)
            energies.append(rms_energy(data))
        except Exception:
            continue
    if energies:
        _noise_floor = float(np.median(energies))
        _noise_calibrated = True
        logger.info("ðŸŽ¤ Bruit ambiant calibrÃ© : %.0f RMS (seuil adaptatif : %.0f)",
                     _noise_floor, _noise_floor * ADAPTIVE_MULTIPLIER)
    return _noise_floor


def get_adaptive_threshold(fixed_threshold: float) -> float:
    """Retourne le seuil VAD adaptatif (max entre fixe et adaptatif)."""
    if _noise_calibrated and _noise_floor > 0:
        adaptive = _noise_floor * ADAPTIVE_MULTIPLIER
        # Prendre le max pour Ã©viter les faux positifs, mais plafonner
        # pour ne pas devenir sourd dans un environnement bruyant
        return max(min(adaptive, fixed_threshold * 1.5), fixed_threshold * 0.5)
    return fixed_threshold


async def capture_utterance(
    stream,
    sample_rate: int = 16000,
    chunk_size: int = 1024,
    voice_threshold: float = DEFAULT_VOICE_THRESHOLD,
    silence_chunks_end: int = DEFAULT_SILENCE_CHUNKS,
    min_sec: float = DEFAULT_MIN_UTTERANCE_SEC,
    max_sec: float = DEFAULT_MAX_UTTERANCE_SEC,
    timeout_sec: Optional[float] = None,
) -> bytes:
    """Capture une utterance complÃ¨te : attend la voix, accumule jusqu'au silence.

    Utilise un seuil adaptatif basÃ© sur le bruit ambiant calibrÃ© au dÃ©marrage.

    Args:
        stream: PyAudio stream ouvert en input
        sample_rate: FrÃ©quence d'Ã©chantillonnage
        chunk_size: Taille de chaque chunk lu
        voice_threshold: Seuil RMS fixe pour dÃ©tecter la voix (ajustÃ© par adaptif)
        silence_chunks_end: Nombre de chunks silencieux consÃ©cutifs = fin d'utterance
        min_sec: DurÃ©e minimum d'une utterance valide
        max_sec: DurÃ©e maximum (sÃ©curitÃ©)
        timeout_sec: Abandon si aucune voix aprÃ¨s ce dÃ©lai (None = infini)

    Returns:
        Audio bytes PCM16 de l'utterance, ou b"" si timeout/trop court
    """
    # Calibration initiale du bruit ambiant (une seule fois)
    global _noise_calibrated
    if not _noise_calibrated:
        calibrate_noise_floor(stream, chunk_size)

    # Seuil adaptatif
    effective_threshold = get_adaptive_threshold(voice_threshold)

    buffer = b""
    silent_count = 0
    voice_detected = False
    voice_chunks = 0       # Nombre de chunks avec de la voix rÃ©elle
    total_chunks = 0
    max_chunks = int(max_sec * sample_rate / chunk_size)
    timeout_chunks = int(timeout_sec * sample_rate / chunk_size) if timeout_sec else None
    wait_chunks = 0
    min_voice = DEFAULT_MIN_VOICE_CHUNKS

    while total_chunks < max_chunks:
        try:
            data = stream.read(chunk_size, exception_on_overflow=False)
        except Exception:
            await asyncio.sleep(0.01)
            continue

        energy = rms_energy(data)

        if not voice_detected:
            if energy > effective_threshold:
                voice_detected = True
                buffer = data
                silent_count = 0
                voice_chunks = 1
                total_chunks = 1
            else:
                wait_chunks += 1
                if timeout_chunks and wait_chunks >= timeout_chunks:
                    return b""  # Timeout, personne n'a parlÃ©
                await asyncio.sleep(0.001)
                continue
        else:
            buffer += data
            total_chunks += 1

            if energy < effective_threshold:
                silent_count += 1
                if silent_count >= silence_chunks_end:
                    break
            else:
                silent_count = 0
                voice_chunks += 1

        await asyncio.sleep(0.001)

    # VÃ©rifier durÃ©e minimum
    duration = len(buffer) / (sample_rate * 2)  # PCM16 = 2 bytes/sample
    if duration < min_sec:
        return b""

    # VÃ©rifier qu'il y avait assez de voix rÃ©elle (pas juste un pic de bruit)
    if voice_chunks < min_voice:
        return b""

    return buffer
