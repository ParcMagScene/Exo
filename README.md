# ğŸ¤– EXO â€” Assistant Vocal Personnel

Assistant IA vocal avec wake word, domotique intÃ©grÃ©e et architecture distribuÃ©e multi-room.

**Stack** : Faster-Whisper (STT) â†’ GPT-4o-mini (LLM) â†’ Kokoro TTS (voix) â†’ Pygame (playback)

---

## Table des matiÃ¨res

- [DÃ©marrage rapide](#-dÃ©marrage-rapide)
- [Architecture](#-architecture)
- [Pipeline vocal](#-pipeline-vocal)
- [Configuration](#-configuration)
- [Variables d'environnement](#-variables-denvironnement)
- [Tests](#-tests)
- [Installation & DÃ©ploiement](#-installation--dÃ©ploiement)

---

## âš¡ DÃ©marrage Rapide

```bash
# 1. Clone + virtual env
cd d:/Exo
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # Linux/Mac

# 2. Installer
pip install -r requirements.txt

# 3. Config
copy .env.example .env
# Ã‰diter .env : ajouter OPENAI_API_KEY (minimum requis)

# 4. Lancer
python main.py
```

Dites **Â« Exo Â»** suivi de votre commande. Ctrl+C pour quitter.

---

## ğŸ—ï¸ Architecture

### Vue d'ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVEUR CENTRAL (PC)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              CORE (core.py)                              â”‚ â”‚
â”‚  â”‚  Machine d'Ã©tats: IDLEâ†’LISTENINGâ†’PROCESSINGâ†’RESPONDING  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â–²              â–²              â–²                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚   WYOMING  â”‚  â”‚   BRAIN    â”‚  â”‚     HOME    â”‚          â”‚
â”‚    â”‚   (audio)  â”‚  â”‚   (LLM)    â”‚  â”‚   BRIDGE    â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                 â”‚                â”‚                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”            â”‚
â”‚    â”‚HARDWAREâ”‚ â”‚MEMORY â”‚ â”‚ GUI â”‚ â”‚ HA  â”‚ â”‚MUSICâ”‚             â”‚
â”‚    â”‚ ACCEL  â”‚ â”‚(CHROMA)â”‚ â”‚(PYG)â”‚ â”‚(WS) â”‚ â”‚(MPD)â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                                  â”‚
         â”‚ Wyoming Protocol (WS)            â”‚ WebSocket
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Pi Zero/5 â”‚                  â”‚ Home Assistant  â”‚
    â”‚(satellites)â”‚                  â”‚  + Domotique   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Structure du code

```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ core.py              # Orchestrateur (machine d'Ã©tats)
â”‚   â””â”€â”€ listener.py          # Boucle d'Ã©coute : micro â†’ VAD â†’ STT â†’ Brain â†’ TTS
â”œâ”€â”€ audio/
â”‚   â””â”€â”€ wake_word.py         # VAD adaptatif + dÃ©tection wake word "Exo"
â”œâ”€â”€ brain/
â”‚   â”œâ”€â”€ brain_engine.py      # LLM (GPT-4o-mini) + RAG ChromaDB + Function Calling
â”‚   â””â”€â”€ local_info.py        # Contexte temps rÃ©el (heure, mÃ©tÃ©o)
â”œâ”€â”€ assistant/
â”‚   â””â”€â”€ tts_client.py        # TTS cascade : Kokoro â†’ Piper â†’ OpenAI
â”œâ”€â”€ integrations/
â”‚   â””â”€â”€ home_bridge.py       # Home Assistant WebSocket + REST
â”œâ”€â”€ gui/
â”‚   â””â”€â”€ visage_gui.py        # Avatar Pygame (Ã©tats synchronisÃ©s, 144Hz)
â””â”€â”€ protocols/
    â””â”€â”€ wyoming.py           # Serveur audio distribuÃ© multi-room (port 10700)
```

### MatÃ©riel

| Composant | Description |
|-----------|-------------|
| **Serveur** | PC Windows/Linux (CPU suffisant, GPU optionnel) |
| **Satellites** | Raspberry Pi Zero 2 W / Pi 5 (via Wyoming protocol) |
| **Domotique** | Home Assistant (HUE, IKEA, Samsung, EZWIZ, Petkit) |

### Flux de donnÃ©es

```
1. Audio capturÃ© (PyAudio 16kHz mono PCM16)
       â–¼
2. VAD adaptatif dÃ©tecte la parole (RMS energy + calibration bruit)
       â–¼
3. Whisper STT transcrit en texte franÃ§ais
       â–¼
4. Wake word "Exo" dÃ©tectÃ© â†’ commande extraite
       â–¼
5. BrainEngine : contexte RAG (ChromaDB) + contexte local (heure/mÃ©tÃ©o)
   â†’ GPT-4o-mini avec Function Calling
       â–¼
6. Actions exÃ©cutÃ©es (domotique, musique, mÃ©moire)
       â–¼
7. RÃ©ponse vocale : Kokoro TTS â†’ Pygame playback
```

### ChromaDB â€” Base de connaissances

| Collection | Contenu |
|------------|---------|
| **animals** | Infos animaux ("Felix est un chat noir, aime les zones chaudes") |
| **house_plan** | Architecture maison ("Salon: 3 HUE, 1 IKEA, TV Samsung") |
| **user_preferences** | PrÃ©fÃ©rences ("LumiÃ¨re chaude le soir 2700K, Jazz au rÃ©veil") |

### Machine d'Ã©tats

```
IDLE â†’ LISTENING (audio reÃ§u) â†’ PROCESSING (STT + LLM) â†’ RESPONDING (TTS) â†’ IDLE
```

L'avatar GUI synchronise ses animations (yeux, spectre audio) sur ces Ã©tats.

---

## ğŸ¤ Pipeline Vocal

```
Microphone (PyAudio 16kHz)
    â†’ VAD Adaptatif (RMS energy, calibration auto)
    â†’ Faster-Whisper "base" (beam=1, CPU)
    â†’ Wake Word "Exo" (13 variantes)
    â†’ BrainEngine (GPT-4o-mini + RAG)
    â†’ Kokoro TTS (24kHz, ff_siwis)
    â†’ Pygame playback
```

### VAD â€” Voice Activity Detection

DÃ©tection par Ã©nergie RMS avec seuil adaptatif calibrÃ© au dÃ©marrage.

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| `VOICE_THRESHOLD` | 300 RMS | Seuil fixe (ajustÃ© par l'adaptatif) |
| `SILENCE_CHUNKS` | 8 (~0.5s) | Silence requis pour fin d'utterance |
| `MIN_UTTERANCE_SEC` | 0.5s | DurÃ©e minimum valide |
| `MIN_VOICE_CHUNKS` | 4 | Chunks vocaux minimum (filtre bruit) |
| `EXO_VAD_MULTIPLIER` | 2.5 | Multiplicateur bruit â†’ seuil |

**Calibration** : 30 chunks de bruit ambiant (mÃ©diane RMS) Ã— multiplicateur, bornÃ© Â±50% du seuil fixe.

### STT â€” Faster-Whisper

ExÃ©cution dans un thread executor (non-bloquant). Filtre automatique des hallucinations Whisper ("sous-titres", "amara.org"...).

| ParamÃ¨tre | Valeur |
|-----------|--------|
| ModÃ¨le | `base` (configurable : tiny/base/small/medium/large) |
| beam_size | 1 (greedy) |
| Langue | FR forcÃ© |
| Latence | ~0.5-1.5s |

### Wake Word

13 variantes reconnues : exo, Ã©cho, echo, expo, ego, exc, exot, x.o, x o, exau, exeau, exos, exho

Extraction : "Exo, quelle heure ?" â†’ "quelle heure ?"

### TTS â€” Cascade

| PrioritÃ© | Moteur | Type | Latence |
|----------|--------|------|---------|
| 1 | **Kokoro** | Local 24kHz | ~0.8s |
| 2 | Piper | Local | ~0.3s |
| 3 | OpenAI TTS-1 | API | ~1-2s |
| 4 | Fish-Speech | API | Variable |
| 5 | Coqui VITS | Local | ~2-3s |

### Latence End-to-End

| Ã‰tape | DurÃ©e typique |
|-------|---------------|
| Capture VAD | 0.5-1s |
| Whisper STT | 0.5-1.5s |
| Brain GPT-4o-mini | 0.5-1.5s |
| Kokoro TTS | ~0.8s |
| **Total** | **~2-4s** |

---

## ğŸ”§ Configuration

### .env minimal

```env
# LLM (au moins un requis)
OPENAI_API_KEY=sk-...                # OpenAI standard (prioritaire)
# ou Azure :
# AZURE_OPENAI_ENDPOINT=https://...
# AZURE_OPENAI_KEY=...

# Domotique (optionnel)
HA_URL=http://homeassistant.local:8123
HA_TOKEN=eyJ0eXAi...
```

---

## ğŸ“‹ Variables d'environnement

### LLM

```env
# â”€â”€ OpenAI standard (prioritaire) â”€â”€
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini           # ModÃ¨le Ã  utiliser

# â”€â”€ Azure OpenAI (fallback) â”€â”€
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_KEY=...
AZURE_OPENAI_DEPLOYMENT=gpt-4o
AZURE_OPENAI_API_VERSION=2024-02-15-preview
```

### Home Assistant

```env
HA_URL=http://homeassistant.local:8123
HA_TOKEN=eyJ0eXAi...               # Long-lived access token
```

### STT & VAD

```env
WHISPER_MODEL=base                  # tiny|base|small|medium|large
WHISPER_WORKERS=8                   # Workers multi-thread (adapter au CPU)
DEVICE=auto                         # auto|cuda|cpu|hip
EXO_VAD_MULTIPLIER=2.5             # SensibilitÃ© (plus bas = plus sensible)
```

### TTS

```env
TTS_ENGINE=kokoro                   # kokoro|piper|openai|fish|coqui
KOKORO_VOICE=ff_siwis               # ff_siwis|ff_alma|fm_music
KOKORO_LANG=f                       # f=franÃ§ais|e=english|j=japanese
KOKORO_ENABLED=true
PIPER_MODEL=models/piper/fr_FR-siwis-medium.onnx
PIPER_ENABLED=true
FISH_SPEECH_URL=http://localhost:8000
TTS_FALLBACK=true
TTS_TIMEOUT=30
TTS_RETRIES=2
```

### Musique / GUI / Wyoming / Logging

```env
# Musique
MOPIDY_URL=http://localhost:6680
TIDAL_QUALITY=LOSSLESS              # LOSSLESS|HI_RES|MASTER|NORMAL

# GUI
GUI_WIDTH=800
GUI_HEIGHT=600
GUI_FPS=144
ENABLE_PYGAME=true

# Wyoming (multi-room)
WYOMING_HOST=0.0.0.0
WYOMING_PORT=10700

# Logging
LOG_LEVEL=INFO                      # DEBUG|INFO|WARNING|ERROR
DEBUG=false
MOCK_HA=false
```

### SÃ©curitÃ©

- Ne **jamais** committer `.env` dans Git
- Ne **jamais** exposer les clÃ©s API publiquement
- Token HA = permissions minimales nÃ©cessaires

---

## ğŸ› ï¸ Tests

```bash
# Diagnostic micro + VAD + STT en temps rÃ©el
python examples/test_pipeline_monitor.py --rounds 5

# Test E2E complet (micro â†’ Brain â†’ TTS â†’ playback)
python examples/test_e2e_vocal.py

# Test BrainEngine seul (LLM + RAG, sans micro)
python examples/test_conversation.py
```

---

## ğŸ“¦ Installation & DÃ©ploiement

Guide complet (PC, Raspberry Pi, Docker, troubleshooting) : **[SETUP.md](SETUP.md)**

```bash
# PC â€” Lancer
python main.py

# Raspberry Pi satellite
python examples/pi_satellite.py --server 192.168.1.50 --port 10700

# Docker
docker-compose up -d
```

---

## ğŸ“œ Licence

Projet privÃ©. Usage personnel uniquement.
