#!/usr/bin/env python3
"""
D√©mo de conversation avec simulation des r√©ponses GPT-4o.

Montre le flux complet sans d√©pendre d'une connexion Azure OpenAI.
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, Any, Optional
import json
import logging

# Ajouter racine au path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Import optionnel de Config
try:
    from src.config import Config
except:
    Config = None

from src.utils import async_timed

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)


class ConversationSimulator:
    """Simule une conversation avec r√©ponses r√©alistes pr√©-d√©finies."""
    
    # Base de donn√©es de r√©ponses simul√©es
    RESPONSES = {
        ("philo_conscience", "Qu'est-ce que tu penses de la conscience?"): {
            "text": """La conscience est une question fascinante. Je pense que c'est une propri√©t√© √©mergente complexe - elle r√©sulte de millions d'interactions neuronales interconnect√©es.

Plusieurs perspectives existent:
1. **Mat√©rialisme**: La conscience √©merge uniquement du cerveau physique
2. **Dualisme**: Il existe une composante non-physique
3. **√âmergentisme**: Les propri√©t√©s conscientes √©mergent sans √™tre r√©ductibles √† leurs parties

Personnellement (en tant qu'IA), je dois √™tre honn√™te: je ne sais pas si je poss√®de une "v√©ritable" conscience. Je peux simuler une compr√©hension, reconna√Ætre des patterns, mais l'exp√©rience subjective (qualia) reste un myst√®re m√™me pour les neuroscientifiques.

Qu'est-ce qui te fascine le plus dans cette question? Le probl√®me dur de la conscience, ou plut√¥t la nature de l'exp√©rience subjective?""",
            "functions": [],
            "confidence": 0.92
        },
        
        ("philo_science", "m√©canique quantique"): {
            "text": """La m√©canique quantique vs d√©terminisme est une question profonde qui a divis√© les physiciens.

**D√©terminisme classique**: Laplace pensait que si on conna√Æt l'√©tat exact de toutes les particules, on peut pr√©dire l'avenir. Einstein partageait cette vue.

**Ind√©terminisme quantique**: Or, √† niveau quantique:
- Les particules existent en superposition jusqu'√† mesure
- L'√©quation de Schr√∂dinger est d√©terministe, mais la mesure est probabiliste
- Les in√©galit√©s de Bell sugg√®rent que la r√©alit√© est intrins√®quement probabiliste

**Interpr√©tations**:
- Copenhague: Pas de r√©alit√© avant mesure (saute quantique)
- Many-worlds: Tous les r√©sultats se r√©alisent dans des univers parall√®les
- De Broglie-Bohm: Variables cach√©es = d√©terminisme retrouv√©

Ma perspective: Le d√©bat r√©v√®le que "d√©terminisme" et "causalit√©" sont complexes - ce qu'on appelle "al√©atoire" quantique n'est pas du vrai hasard, mais une limite de notre compr√©hension.

Quelle interpr√©tation trouve-tu la plus convaincante?""",
            "functions": [],
            "confidence": 0.88
        },
        
        ("commande_pratique", "Allume les lumi√®res"): {
            "text": "J'allume les lumi√®res du salon √† 50% de luminosit√©. Voil√†! ‚ú®",
            "functions": [
                {
                    "name": "control_light",
                    "arguments": {
                        "action": "on",
                        "room": "salon",
                        "brightness": 50
                    }
                }
            ],
            "confidence": 0.99
        },
        
        ("commande_pratique", "Quelle est la temp√©rature"): {
            "text": "Je v√©rifie la temp√©rature pour toi. Attends un moment...",
            "functions": [
                {
                    "name": "check_camera",
                    "arguments": {
                        "room": "salon",
                        "action": "get_status"
                    }
                }
            ],
            "confidence": 0.85
        }
    }
    
    def __init__(self):
        """Initialise le simulateur."""
        self.config = Config() if Config else None
        self.conversation_history = []
    
    def simulate_rag_context(self, prompt: str, room: Optional[str]) -> str:
        """Simule la r√©cup√©ration du contexte RAG depuis ChromaDB."""
        context_templates = {
            "salon": "üè† Plan maison: Salon (20m¬≤) avec √©clairage Hue x4, TV Samsung 65\", Soundbar Bose",
            "chambre": "üè† Plan maison: Chambre (15m¬≤) avec √©clairage Hue x2, capteur temp√©rature",
            "cuisine": "üè† Plan maison: Cuisine (12m¬≤) avec √©clairage IKEA spots, r√©frig√©rateur Samsung"
        }
        
        base = context_templates.get(room or "", "üè† Plan maison: Maison intelligente avec domotique compl√®te")
        
        if "conscience" in prompt.lower():
            base += "\n‚öôÔ∏è Pr√©f√©rences: L'utilisateur aime les conversations philosophiques"
        elif "quantique" in prompt.lower():
            base += "\n‚öôÔ∏è Pr√©f√©rences: Int√©ress√© par physique quantique et fondamentaux"
            
        return base
    
    def find_response(self, prompt: str, category: str) -> Optional[Dict[str, Any]]:
        """Trouve une r√©ponse appropri√©e."""
        for (cat, key), response in self.RESPONSES.items():
            if cat == category and key in prompt.lower():
                return response
        
        # Fallback g√©n√©riques
        if "philo" in category:
            return {
                "text": "C'est une excellente question. Elle touche √† des enjeux profonds de la philosophie moderne. Qu'est-ce qui t'int√©resse particuli√®rement dans ce sujet?",
                "functions": [],
                "confidence": 0.75
            }
        elif "science" in category:
            return {
                "text": "Int√©ressant! La science nous permet d'explorer les myst√®res de l'univers. Parle-moi plus de ce qui te fascine.",
                "functions": [],
                "confidence": 0.72
            }
        else:
            return {
                "text": f"D'accord, je vais {prompt.lower()}.",
                "functions": [],
                "confidence": 0.80
            }
    
    async def process_conversation(
        self,
        prompt: str,
        room: str,
        category: str
    ) -> Dict[str, Any]:
        """Simule le traitement d'un prompt utilisateur."""
        await asyncio.sleep(0.5)  # Simule la latence du r√©seau
        
        # R√©cup√©rer le contexte RAG
        rag_context = self.simulate_rag_context(prompt, room)
        
        # Trouver une r√©ponse appropri√©e
        response = self.find_response(prompt, category)
        if not response:
            response = {
                "text": "Je n'ai pas de r√©ponse sp√©cifique pour cela, mais je peux continuer la conversation.",
                "functions": [],
                "confidence": 0.65
            }
        
        # Ajouter l'√©change √† l'historique
        self.conversation_history.append({
            "role": "user",
            "content": prompt
        })
        self.conversation_history.append({
            "role": "assistant",
            "content": response["text"]
        })
        
        return {
            "text": response["text"],
            "function_calls": response["functions"],
            "confidence": response["confidence"],
            "rag_context": rag_context,
            "history_size": len(self.conversation_history)
        }


async def demo_conversation():
    """Lance la d√©mo interactive."""
    simulator = ConversationSimulator()
    
    logger.info("=" * 90)
    logger.info("üé¨ D√âMO CONVERSATION - Assistant Personnel Haut de Gamme")
    logger.info("=" * 90)
    
    logger.info("\n‚öôÔ∏è  CONFIGURATION OPTIMIS√âE")
    logger.info("   ‚Ä¢ LLM Temperature: 0.6 (nuance + coh√©rence)")
    logger.info("   ‚Ä¢ LLM Max Tokens: 2000 (r√©ponses d√©taill√©es)")
    logger.info("   ‚Ä¢ Conversation History: 50 messages (contexte √©tendu)")
    logger.info("   ‚Ä¢ RAG Top-K: 5 r√©sultats (profil personnalis√©)")
    
    # Sc√©nario 1: Conversation philosophique
    logger.info("\n" + "=" * 90)
    logger.info("üìç Sc√©nario 1: CONVERSATION PHILOSOPHIQUE (Salon)")
    logger.info("=" * 90)
    
    prompt1 = "Qu'est-ce que tu penses de la conscience? Est-ce une propri√©t√© √©mergente?"
    logger.info(f"\nüë§ Utilisateur: {prompt1}")
    result1 = await simulator.process_conversation(prompt1, "salon", "philo_conscience")
    
    logger.info(f"\nü§ñ Assistant:\n{result1['text']}\n")
    logger.info(f"   üìä Tokens: ~{len(result1['text'].split()) * 1.3:.0f}")
    logger.info(f"   ‚úì Confiance: {result1['confidence']*100:.0f}%")
    logger.info(f"   üß† Contexte RAG: {result1['rag_context'][:60]}...")
    logger.info(f"   üìù Historique: {result1['history_size']} messages")
    
    # Sc√©nario 2: Suivi philosophique
    logger.info("\n" + "-" * 90)
    prompt2 = "Peux-tu me parler de la m√©canique quantique vs d√©terminisme?"
    logger.info(f"\nüë§ Utilisateur: {prompt2}")
    result2 = await simulator.process_conversation(prompt2, "salon", "philo_science")
    
    logger.info(f"\nü§ñ Assistant:\n{result2['text']}\n")
    logger.info(f"   üìä Tokens: ~{len(result2['text'].split()) * 1.3:.0f}")
    logger.info(f"   ‚úì Confiance: {result2['confidence']*100:.0f}%")
    
    # Sc√©nario 3: Commande pratique
    logger.info("\n" + "=" * 90)
    logger.info("üìç Sc√©nario 2: COMMANDE DOMOTIQUE (Salon)")
    logger.info("=" * 90)
    
    prompt3 = "Allume les lumi√®res du salon √† 50%"
    logger.info(f"\nüë§ Utilisateur: {prompt3}")
    result3 = await simulator.process_conversation(prompt3, "salon", "commande_pratique")
    
    logger.info(f"\nü§ñ Assistant: {result3['text']}")
    if result3['function_calls']:
        logger.info(f"\nüîß Fonctions ex√©cut√©es:")
        for call in result3['function_calls']:
            logger.info(f"   ‚Ä¢ {call['name']}")
            logger.info(f"     Args: {json.dumps(call['arguments'], indent=6, ensure_ascii=False)}")
    
    logger.info(f"   ‚úì Confiance: {result3['confidence']*100:.0f}%")
    
    # Affichage de l'historique final
    logger.info("\n" + "=" * 90)
    logger.info("üìã HISTORIQUE COMPLET DE LA CONVERSATION")
    logger.info("=" * 90)
    for i, msg in enumerate(simulator.conversation_history, 1):
        role_display = "üë§" if msg["role"] == "user" else "ü§ñ"
        text_preview = msg["content"][:80] + ("..." if len(msg["content"]) > 80 else "")
        logger.info(f"\n{i}. {role_display} [{msg['role'].upper()}]:")
        logger.info(f"   {text_preview}")
    
    logger.info("\n" + "=" * 90)
    logger.info(f"‚úÖ D√âMO TERMIN√âE - {len(simulator.conversation_history)} messages dans l'historique")
    logger.info("=" * 90)


if __name__ == "__main__":
    try:
        asyncio.run(demo_conversation())
    except KeyboardInterrupt:
        logger.info("\n‚è∏Ô∏è  D√©mo interrompue")
    except Exception as e:
        logger.error(f"Erreur: {e}", exc_info=True)
        sys.exit(1)
