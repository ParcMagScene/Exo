#!/usr/bin/env python3
"""
Test d'une conversation compl√®te de bout en bout.

Simule une interaction utilisateur avec le BrainEngine optimis√© pour les conversations.
Montre comment le syst√®me:
1. R√©cup√®re le contexte RAG
2. Construit le prompt syst√®me enrichi
3. Appelle GPT-4o avec les param√®tres optimis√©s
4. Parse la r√©ponse et extrait les function calls
"""

import asyncio
import sys
import json
from pathlib import Path

# Ajouter racine au path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.brain.brain_engine import BrainEngine
from src.config import Config
from src.utils import async_timed
import logging

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)


class ConversationTester:
    """Testeur de conversations pour d√©montrer les capacit√©s."""
    
    def __init__(self):
        """Initialise le testeur."""
        self.config = Config()
        self.brain = BrainEngine(self.config)
        
    async def run_test_suite(self):
        """Ex√©cute une suite de tests de conversation."""
        logger.info("=" * 80)
        logger.info("üß† TEST DE CONVERSATION - Assistant Personnel Haut de Gamme")
        logger.info("=" * 80)
        
        # Simuler des conversations vari√©es
        conversations = [
            {
                "room": "salon",
                "messages": [
                    ("Qu'est-ce que tu penses de la conscience? Est-ce une propri√©t√© √©mergente?", 
                     "philo_conscience"),
                    ("Peux-tu me parler de la m√©canique quantique vs d√©terminisme?", 
                     "philo_science"),
                    ("Allume les lumi√®res du salon √† 50%", 
                     "commande_pratique"),
                ]
            }
        ]
        
        for conversation in conversations:
            room = conversation["room"]
            logger.info(f"\nüìç Pi√®ce: {room}")
            logger.info("-" * 80)
            
            for prompt, category in conversation["messages"]:
                await self._test_single_prompt(prompt, room, category)
                print("\n")
    
    @async_timed
    async def _test_single_prompt(
        self, 
        prompt: str, 
        room: str, 
        category: str
    ) -> None:
        """Teste un prompt unique."""
        logger.info(f"\nüë§ Input [{category}]: {prompt}")
        logger.info("-" * 40)
        
        try:
            # Appel au BrainEngine avec les param√®tres optimis√©s
            result = await self.brain.process_command(
                text=prompt,
                room=room,
                context={"category": category}
            )
            
            # Affichage de la r√©ponse
            response_text = result.get("text", "")
            if response_text:
                logger.info(f"ü§ñ R√©ponse: {response_text[:300]}...")
                
                # Montre la longueur de la r√©ponse
                token_estimate = len(response_text.split()) * 1.3  # Approximation
                logger.info(f"   üìä Longueur: ~{int(token_estimate)} tokens")
            
            # Montre les function calls si pr√©sents
            function_calls = result.get("function_calls", [])
            if function_calls:
                logger.info(f"üîß Fonction(s) d√©tect√©e(s):")
                for call in function_calls:
                    logger.info(f"   ‚Ä¢ {call.get('name')}: {call.get('arguments')}")
            
            # Confiance du syst√®me
            confidence = result.get("confidence", 0)
            logger.info(f"   ‚úì Confiance: {confidence * 100:.0f}%")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du traitement: {e}", exc_info=True)
    
    def print_config_summary(self):
        """Affiche un r√©sum√© de la configuration optimis√©e."""
        logger.info("\n" + "=" * 80)
        logger.info("‚öôÔ∏è  CONFIGURATION OPTIMIS√âE POUR CONVERSATIONS")
        logger.info("=" * 80)
        logger.info(f"LLM Temperature: 0.6 (balance nuance/coh√©rence)")
        logger.info(f"LLM Max Tokens: 2000 (long-form responses)")
        logger.info(f"Conversation History: 50 messages (contexte √©tendu)")
        logger.info(f"RAG Top-K: 5 (profil personnalis√©)")
        logger.info("\n[PROMPT SYST√àME]")
        logger.info("‚Ä¢ Assistant domotique (HUE, IKEA, Samsung, etc.)")
        logger.info("‚Ä¢ Compagnon conversationnel (philo, science, empathie)")
        logger.info("‚Ä¢ Honn√™te sur ses limites")
        logger.info("‚Ä¢ Reconna√Æt l'ambigu√Øt√© et l'incertitude")


async def main():
    """Fonction principale."""
    tester = ConversationTester()
    
    # Afficher la configuration
    tester.print_config_summary()
    
    # Ex√©cuter les tests
    try:
        await tester.run_test_suite()
        logger.info("\n" + "=" * 80)
        logger.info("‚úÖ SESSION DE TEST TERMIN√âE")
        logger.info("=" * 80)
    except KeyboardInterrupt:
        logger.info("\n‚è∏Ô∏è  Test interrompu par l'utilisateur")
    except Exception as e:
        logger.error(f"Erreur lors du test: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
