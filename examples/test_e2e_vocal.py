#!/usr/bin/env python3
"""
Test E2E Pipeline â€” EXO bout en bout avec rÃ©ponse vocale.

Pipeline complet :
  Micro â†’ VAD â†’ Capture â†’ Whisper STT â†’ Wake word â†’ Brain (GPT-4o-mini) â†’ Kokoro TTS â†’ Playback

Usage:
  python examples/test_e2e_vocal.py
  python examples/test_e2e_vocal.py --rounds 3
"""

import asyncio
import argparse
import sys
import os
import io
import time
import logging
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

os.environ.setdefault("SUPPRESS_CONFIG_WARNINGS", "1")
os.environ.setdefault("HF_HUB_DISABLE_XET", "1")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("e2e_vocal")

# â”€â”€â”€ Couleurs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
G = "\033[92m"
Y = "\033[93m"
R = "\033[91m"
C = "\033[96m"
B = "\033[1m"
RST = "\033[0m"

SAMPLE_RATE = 16000
CHUNK_SIZE = 1024
FOLLOWUP_TIMEOUT = 7.0


async def main():
    parser = argparse.ArgumentParser(description="Test E2E EXO â€” pipeline vocal complet")
    parser.add_argument("--rounds", type=int, default=3, help="Nombre de tours (default: 3)")
    parser.add_argument("--whisper", type=str, default=os.environ.get("WHISPER_MODEL", "base"))
    parser.add_argument("--device", type=int, default=None)
    args = parser.parse_args()

    import pyaudio
    import numpy as np

    print(f"\n{B}{'â•' * 60}")
    print(f"  EXO â€” TEST E2E COMPLET (avec rÃ©ponse vocale)")
    print(f"  Dites Â« Exo Â» suivi de votre commande")
    print(f"{'â•' * 60}{RST}\n")

    # â”€â”€ 1. Micro â”€â”€
    pa = pyaudio.PyAudio()
    if args.device is None:
        try:
            info = pa.get_default_input_device_info()
            dev_idx = int(info["index"])
        except Exception:
            dev_idx = 0
    else:
        dev_idx = args.device

    dev_info = pa.get_device_info_by_index(dev_idx)
    print(f"  ğŸ¤ Micro : {dev_info['name']} (index {dev_idx})")

    stream = pa.open(
        format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE,
        input=True, input_device_index=dev_idx, frames_per_buffer=CHUNK_SIZE,
    )

    # â”€â”€ 2. Whisper â”€â”€
    print(f"  â³ Chargement Whisper ({args.whisper})...", end="", flush=True)
    from faster_whisper import WhisperModel
    t0 = time.time()
    loop = asyncio.get_running_loop()
    whisper = await loop.run_in_executor(
        None, lambda: WhisperModel(args.whisper, device="cpu", compute_type="float32"),
    )
    print(f" OK ({time.time() - t0:.1f}s)")

    def transcribe(audio_bytes: bytes) -> str:
        samples = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
        if len(samples) < 4800:
            return ""
        segments, _ = whisper.transcribe(samples, language="fr", beam_size=1)
        return " ".join(seg.text for seg in segments).strip()

    # â”€â”€ 3. Brain â”€â”€
    print(f"  â³ Chargement BrainEngine...", end="", flush=True)
    from src.brain.brain_engine import BrainEngine
    brain = BrainEngine()
    await brain.initialize()
    print(f" OK")

    # â”€â”€ 4. TTS â”€â”€
    print(f"  â³ Chargement TTS...", end="", flush=True)
    from src.assistant.tts_client import TTSClient
    tts = TTSClient()
    tts.preload()
    print(f" OK (engine={tts.preferred_engine}, {tts.sample_rate}Hz)")

    # â”€â”€ 5. Pygame mixer â”€â”€
    import pygame
    pygame.mixer.init(frequency=tts.sample_rate, size=-16, channels=1)
    print(f"  âœ… Pygame mixer OK ({tts.sample_rate}Hz)")

    # â”€â”€ 6. Calibration VAD â”€â”€
    from src.audio.wake_word import (
        calibrate_noise_floor, capture_utterance,
        contains_wake_word, extract_command_after_wake, is_hallucination,
    )
    print(f"  ğŸ”‡ Calibration bruit ambiant...", end="", flush=True)
    noise = calibrate_noise_floor(stream, CHUNK_SIZE)
    print(f" OK (bruit={noise:.0f} RMS)")

    # â”€â”€ Warm-up Whisper (1er appel lent) â”€â”€
    print(f"  ğŸ”¥ Warm-up Whisper...", end="", flush=True)
    silence = b'\x00' * (SAMPLE_RATE * 2)  # 1s silence
    await loop.run_in_executor(None, transcribe, silence)
    print(f" OK")

    print(f"\n{B}{'â•' * 60}")
    print(f"  PRÃŠT â€” Dites Â« Exo, <commande> Â» ({args.rounds} tours)")
    print(f"{'â•' * 60}{RST}\n")

    results = []

    def flush_mic():
        try:
            avail = stream.get_read_available()
            while avail > 0:
                stream.read(min(avail, CHUNK_SIZE), exception_on_overflow=False)
                avail = stream.get_read_available()
        except Exception:
            pass

    for i in range(args.rounds):
        print(f"  {C}â”€â”€ Tour {i + 1}/{args.rounds} â”€â”€{RST}")
        print(f"  ğŸ‘‚ En Ã©coute... dites Â« Exo, ... Â»\n")

        # â”€â”€ Capture â”€â”€
        t0_pipeline = time.time()
        utterance = await capture_utterance(
            stream, sample_rate=SAMPLE_RATE, chunk_size=CHUNK_SIZE, timeout_sec=20.0,
        )
        capture_time = time.time() - t0_pipeline

        if not utterance:
            print(f"  {Y}â±  Timeout â€” aucune voix{RST}\n")
            results.append({"status": "timeout"})
            continue

        duration = len(utterance) / (SAMPLE_RATE * 2)

        # â”€â”€ STT â”€â”€
        t0_stt = time.time()
        transcript = await loop.run_in_executor(None, transcribe, utterance)
        stt_time = time.time() - t0_stt

        if not transcript or is_hallucination(transcript):
            tag = "hallucination" if transcript else "vide"
            print(f"  {Y}âœ—  Transcription {tag} : Â« {transcript or ''} Â»{RST}\n")
            results.append({"status": tag})
            continue

        print(f"  ğŸ“ STT : Â« {B}{transcript}{RST} Â» (capture={capture_time:.2f}s, STT={stt_time:.2f}s)")

        # â”€â”€ Wake word ? â”€â”€
        if not contains_wake_word(transcript):
            print(f"  â„¹ï¸  Pas de wake word Â« Exo Â» â€” ignorÃ©\n")
            results.append({"status": "no_wake", "text": transcript, "stt_time": stt_time})
            continue

        command = extract_command_after_wake(transcript)
        print(f"  {G}âœ¨ WAKE WORD dÃ©tectÃ© !{RST}")

        # Si juste "Exo" sans commande, attendre la suite
        if len(command.split()) < 2:
            if command:
                print(f"  ğŸ”¸ Fragment : Â« {command} Â» â€” attente suite...")
            else:
                print(f"  ğŸ”¸ Juste Â« Exo Â» â€” attente commande...")
            print(f"  ğŸ¤ Parlez maintenant (timeout {FOLLOWUP_TIMEOUT}s)...")

            followup = b""
            deadline = time.time() + FOLLOWUP_TIMEOUT
            while time.time() < deadline:
                remaining = deadline - time.time()
                if remaining <= 0:
                    break
                followup = await capture_utterance(
                    stream, sample_rate=SAMPLE_RATE, chunk_size=CHUNK_SIZE,
                    min_sec=0.3, timeout_sec=remaining,
                )
                if followup:
                    break

            if not followup:
                print(f"  {Y}â±  Timeout â€” pas de suite aprÃ¨s Â« Exo Â»{RST}\n")
                results.append({"status": "wake_no_cmd"})
                continue

            followup_text = await loop.run_in_executor(None, transcribe, followup)
            if not followup_text:
                print(f"  {Y}âœ—  Suite transcrite vide{RST}\n")
                results.append({"status": "wake_no_cmd"})
                continue

            command = (command + " " + followup_text).strip() if command else followup_text
            print(f"  ğŸ“ Suite : Â« {followup_text} Â»")

        print(f"  {G}ğŸ’¬ Commande : Â« {command} Â»{RST}")

        # â”€â”€ Couper le micro pendant la rÃ©ponse â”€â”€
        stream.stop_stream()

        # â”€â”€ Brain â”€â”€
        t0_brain = time.time()
        result = await brain.process_command(
            text=command, room="local", context={"source": "test_e2e"},
        )
        brain_time = time.time() - t0_brain
        response_text = result.get("text", "")
        function_calls = result.get("function_calls", [])

        print(f"  ğŸ¤– Brain ({brain_time:.2f}s) : Â« {B}{response_text}{RST} Â»")
        if function_calls:
            for fc in function_calls:
                print(f"  ğŸ”§ Action : {fc['name']}({fc['arguments']})")

        # â”€â”€ TTS â”€â”€
        tts_time = 0.0
        play_time = 0.0
        if response_text:
            t0_tts = time.time()
            try:
                audio = await tts.speak(response_text)
                tts_time = time.time() - t0_tts
                print(f"  ğŸ”Š TTS ({tts_time:.2f}s, {len(audio) // 1024}KB)")

                # Playback
                t0_play = time.time()
                sound = pygame.mixer.Sound(io.BytesIO(audio))
                sound.play()
                while pygame.mixer.get_busy():
                    await asyncio.sleep(0.05)
                play_time = time.time() - t0_play
                print(f"  ğŸ”ˆ Playback ({play_time:.2f}s)")
            except Exception as e:
                print(f"  {R}âœ— TTS/Playback erreur : {e}{RST}")
                print(f"  ğŸ“„ RÃ©ponse texte : {response_text}")

        # â”€â”€ Total â”€â”€
        total = time.time() - t0_pipeline
        print(f"\n  {B}â±  TOTAL : {total:.2f}s{RST}")
        print(f"     Capture={capture_time:.2f}s + STT={stt_time:.2f}s + Brain={brain_time:.2f}s + TTS={tts_time:.2f}s + Play={play_time:.2f}s")

        speed = "ğŸŸ¢" if (stt_time + brain_time + tts_time) < 3.0 else ("ğŸŸ¡" if (stt_time + brain_time + tts_time) < 5.0 else "ğŸ”´")
        print(f"     Latence traitement (STT+Brain+TTS) : {stt_time + brain_time + tts_time:.2f}s {speed}\n")

        # â”€â”€ RÃ©activer micro â”€â”€
        stream.start_stream()
        flush_mic()

        results.append({
            "status": "ok",
            "text": transcript,
            "command": command,
            "response": response_text,
            "capture_time": capture_time,
            "stt_time": stt_time,
            "brain_time": brain_time,
            "tts_time": tts_time,
            "play_time": play_time,
            "total_time": total,
            "processing_time": stt_time + brain_time + tts_time,
        })

    # â”€â”€ RÃ©sumÃ© final â”€â”€
    print(f"\n{B}{'â•' * 60}")
    print(f"  RÃ‰SUMÃ‰ E2E")
    print(f"{'â•' * 60}{RST}")

    ok = [r for r in results if r["status"] == "ok"]
    print(f"  Tours complets    : {len(ok)}/{args.rounds}")
    print(f"  Sans wake word    : {sum(1 for r in results if r['status'] == 'no_wake')}")
    print(f"  Timeouts          : {sum(1 for r in results if r['status'] == 'timeout')}")

    if ok:
        avg_proc = sum(r["processing_time"] for r in ok) / len(ok)
        avg_total = sum(r["total_time"] for r in ok) / len(ok)
        print(f"\n  Latence moyenne (STT+Brain+TTS) : {avg_proc:.2f}s")
        print(f"  Temps total moyen (avec capture) : {avg_total:.2f}s")

        print(f"\n  DÃ©tail par tour :")
        for j, r in enumerate(ok):
            print(f"    {j+1}. Â« {r['command'][:50]} Â»")
            print(f"       â†’ Â« {r['response'][:60]} Â»")
            print(f"       STT={r['stt_time']:.2f}s  Brain={r['brain_time']:.2f}s  TTS={r['tts_time']:.2f}s  Total={r['total_time']:.2f}s")

    # Cleanup
    stream.stop_stream()
    stream.close()
    pa.terminate()
    await brain.close()
    pygame.mixer.quit()
    print(f"\n  ğŸ”Œ Ressources libÃ©rÃ©es. Test terminÃ©.\n")


if __name__ == "__main__":
    asyncio.run(main())
