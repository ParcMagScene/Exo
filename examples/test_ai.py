#!/usr/bin/env python3
"""
Test pipeline complet : Ã‰coute micro â†’ Transcription Whisper â†’ RÃ©ponse GPT-4o.

Pipeline E2E:
  1. AudioCapture     â†’ capture micro (PyAudio, 16kHz mono PCM16)
  2. HardwareAccel    â†’ transcription Faster-Whisper (STT)
  3. BrainEngine      â†’ rÃ©ponse GPT-4o (LLM + Function Calling)

Modes:
  --mode full      Pipeline complet (micro â†’ whisper â†’ GPT-4o)
  --mode text      Texte tapÃ© â†’ GPT-4o (sans micro)
  --mode stt       Micro â†’ Whisper uniquement (pas de GPT-4o)
  --duration 5     DurÃ©e d'Ã©coute en secondes (dÃ©faut: 5)
  --silence        Ã‰couter jusqu'au silence au lieu d'une durÃ©e fixe
  --loop           Boucle continue (parler, rÃ©ponse, parler...)
"""

import asyncio
import sys
import os
import time
import logging
import argparse
from pathlib import Path

os.environ["SUPPRESS_CONFIG_WARNINGS"] = "1"
sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)


def print_header(title: str):
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}")


def print_section(title: str):
    print(f"\n  â”€â”€ {title} â”€â”€")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Ã‰TAPE 1 : VÃ©rification des dÃ©pendances
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def check_dependencies() -> dict:
    """VÃ©rifie toutes les dÃ©pendances du pipeline."""
    print_header("VÃ‰RIFICATION DES DÃ‰PENDANCES")

    status = {"pyaudio": False, "whisper": False, "openai": False, "api_key": False}

    # PyAudio
    try:
        import pyaudio  # type: ignore
        pa = pyaudio.PyAudio()
        dev_count = pa.get_device_count()
        default_input = pa.get_default_input_device_info()
        print(f"  âœ“ PyAudio OK â€” {dev_count} devices, dÃ©faut: {default_input['name']}")
        pa.terminate()
        status["pyaudio"] = True
    except Exception as e:
        print(f"  âœ— PyAudio â€” {e}")

    # Faster-Whisper
    try:
        import faster_whisper  # type: ignore
        print(f"  âœ“ Faster-Whisper OK")
        status["whisper"] = True
    except ImportError:
        print(f"  âœ— Faster-Whisper â€” pip install faster-whisper")

    # OpenAI SDK
    try:
        import openai
        print(f"  âœ“ OpenAI SDK {openai.__version__}")
        status["openai"] = True
    except ImportError:
        print(f"  âœ— OpenAI SDK â€” pip install openai")

    # ClÃ© API
    from dotenv import load_dotenv
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY", "")
    if api_key and api_key.startswith("sk-"):
        model = os.getenv("OPENAI_MODEL", "gpt-4o")
        print(f"  âœ“ ClÃ© API OpenAI configurÃ©e (modÃ¨le: {model})")
        status["api_key"] = True
    else:
        azure_key = os.getenv("AZURE_OPENAI_KEY", "")
        if azure_key and azure_key != "your-azure-api-key-here":
            print(f"  âœ“ ClÃ© API Azure OpenAI configurÃ©e")
            status["api_key"] = True
        else:
            print(f"  âœ— Aucune clÃ© API (OPENAI_API_KEY ou AZURE_OPENAI_KEY)")

    return status


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Ã‰TAPE 2 : Capture audio micro
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def capture_audio(duration: float = 5.0, use_silence: bool = False) -> bytes:
    """Capture l'audio depuis le microphone."""
    from src.audio.audio_capture import AudioCapture

    capture = AudioCapture(sample_rate=16000, channels=1)

    if use_silence:
        print(f"\n  ğŸ¤ Parlez maintenant... (arrÃªt automatique au silence)")
        audio_data = await capture.record_until_silence(
            silence_threshold=500,
            silence_duration=1.5,
            max_recording=30.0
        )
    else:
        print(f"\n  ğŸ¤ Parlez maintenant... (enregistrement {duration}s)")
        # Compte Ã  rebours visuel
        audio_data = await capture.record_duration(duration)

    duration_real = len(audio_data) / (16000 * 2)  # 16kHz, 16-bit = 2 bytes/sample
    print(f"  âœ“ Audio capturÃ© : {len(audio_data)} bytes ({duration_real:.1f}s)")

    return audio_data


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Ã‰TAPE 3 : Transcription (Faster-Whisper STT)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def transcribe_audio(audio_data: bytes) -> str:
    """Transcrit l'audio capturÃ© en texte via Faster-Whisper."""
    from src.hardware.hardware_accel import HardwareAccelerator

    print_section("TRANSCRIPTION (Faster-Whisper)")

    accel = HardwareAccelerator()
    await accel.initialize()

    start = time.time()
    text = await accel.transcribe_audio(audio_data)
    elapsed = time.time() - start

    if text:
        print(f"  ğŸ“ Transcription ({elapsed:.2f}s) :")
        print(f"     \"{text}\"")
    else:
        print(f"  âš  Aucun texte dÃ©tectÃ© (silence ou audio trop court)")

    return text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Ã‰TAPE 4 : RÃ©ponse IA (GPT-4o via BrainEngine)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def get_ai_response(text: str, brain=None) -> tuple:
    """Envoie le texte transcrit au BrainEngine et obtient la rÃ©ponse."""
    from src.brain.brain_engine import BrainEngine

    print_section("RÃ‰PONSE IA (GPT-4o)")

    own_brain = brain is None
    if own_brain:
        brain = BrainEngine()
        await brain.initialize()

    print(f"  ğŸ’¬ Envoi : \"{text}\"")

    start = time.time()
    result = await brain.process_command(text)
    elapsed = time.time() - start

    response = result.get("text", "")
    function_calls = result.get("function_calls", [])

    print(f"\n  ğŸ¤– RÃ©ponse IA ({elapsed:.2f}s) :")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    for line in response.split("\n"):
        print(f"    {line}")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    if function_calls:
        print(f"\n  ğŸ”§ Function Calls dÃ©tectÃ©s :")
        for fc in function_calls:
            print(f"    â†’ {fc['name']}({fc['arguments']})")

    if own_brain:
        await brain.close()

    return response, function_calls, brain


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  MODE COMPLET : Micro â†’ Whisper â†’ GPT-4o
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def run_full_pipeline(duration: float, use_silence: bool, loop: bool):
    """Pipeline complet : Ã©coute â†’ transcription â†’ rÃ©ponse IA."""
    print_header("PIPELINE COMPLET : Micro â†’ Whisper â†’ GPT-4o")

    from src.brain.brain_engine import BrainEngine

    brain = BrainEngine()
    await brain.initialize()

    iteration = 0

    try:
        while True:
            iteration += 1
            if loop:
                print(f"\n  â”â”â” Tour {iteration} â”â”â”")

            # Ã‰tape 1 : Ã‰coute micro
            print_section("Ã‰COUTE MICRO")
            audio_data = await capture_audio(duration, use_silence)

            if len(audio_data) < 3200:  # Moins de 0.1s d'audio
                print(f"  âš  Audio trop court, ignorÃ©")
                if not loop:
                    break
                continue

            # Ã‰tape 2 : Transcription
            text = await transcribe_audio(audio_data)

            if not text or not text.strip():
                print(f"  âš  Rien dÃ©tectÃ©. RÃ©essayez.")
                if not loop:
                    break
                continue

            # Ã‰tape 3 : RÃ©ponse IA
            response, fc, brain = await get_ai_response(text, brain=brain)

            if not loop:
                break

            # Pause avant prochain tour
            print(f"\n  â³ PrÃªt pour la prochaine question...")
            await asyncio.sleep(1.0)

    except KeyboardInterrupt:
        print(f"\n\n  âš  ArrÃªt demandÃ© (Ctrl+C)")

    finally:
        await brain.close()
        print(f"\n  âœ… Pipeline terminÃ© ({iteration} Ã©change(s))")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  MODE TEXTE : Taper â†’ GPT-4o
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def run_text_mode(loop: bool):
    """Mode texte : taper sa question au clavier."""
    print_header("MODE TEXTE : Clavier â†’ GPT-4o")
    print("  Tapez votre question (ou 'quit' pour quitter)\n")

    from src.brain.brain_engine import BrainEngine

    brain = BrainEngine()
    await brain.initialize()

    try:
        while True:
            try:
                user_input = input("  Vous > ").strip()
            except EOFError:
                break

            if user_input.lower() in ("quit", "exit", "q"):
                break

            if not user_input:
                continue

            response, fc, brain = await get_ai_response(user_input, brain=brain)

            if not loop:
                break

    except KeyboardInterrupt:
        print(f"\n\n  âš  ArrÃªt demandÃ©")

    finally:
        await brain.close()
        print(f"  âœ… Session terminÃ©e")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  MODE STT : Micro â†’ Whisper uniquement
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def run_stt_mode(duration: float, use_silence: bool, loop: bool):
    """Mode STT uniquement : Ã©coute et transcrit (sans appel IA)."""
    print_header("MODE STT : Micro â†’ Whisper (sans IA)")

    iteration = 0

    try:
        while True:
            iteration += 1
            if loop:
                print(f"\n  â”â”â” Tour {iteration} â”â”â”")

            audio_data = await capture_audio(duration, use_silence)

            if len(audio_data) < 3200:
                print(f"  âš  Audio trop court")
                if not loop:
                    break
                continue

            text = await transcribe_audio(audio_data)

            if not loop:
                break

            await asyncio.sleep(0.5)

    except KeyboardInterrupt:
        print(f"\n\n  âš  ArrÃªt demandÃ©")

    print(f"  âœ… STT terminÃ© ({iteration} transcription(s))")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  MAIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def main():
    parser = argparse.ArgumentParser(
        description="Test pipeline : Ã‰coute â†’ Transcription â†’ RÃ©ponse IA"
    )
    parser.add_argument(
        "--mode", choices=["full", "text", "stt"], default="full",
        help="Mode: full (microâ†’whisperâ†’GPT), text (clavierâ†’GPT), stt (microâ†’whisper)"
    )
    parser.add_argument(
        "--duration", type=float, default=5.0,
        help="DurÃ©e d'Ã©coute en secondes (dÃ©faut: 5)"
    )
    parser.add_argument(
        "--silence", action="store_true",
        help="Ã‰couter jusqu'au silence (au lieu d'une durÃ©e fixe)"
    )
    parser.add_argument(
        "--loop", action="store_true",
        help="Boucle continue (conversation multi-tours)"
    )

    args = parser.parse_args()

    # VÃ©rification dÃ©pendances
    status = await check_dependencies()

    if args.mode in ("full", "stt"):
        if not status["pyaudio"]:
            print("\n  ABANDON â€” PyAudio requis pour le micro")
            return
        if not status["whisper"]:
            print("\n  ABANDON â€” Faster-Whisper requis pour la transcription")
            return

    if args.mode in ("full", "text"):
        if not status["api_key"]:
            print("\n  ABANDON â€” ClÃ© API requise pour GPT-4o")
            return

    # Lancement du mode choisi
    if args.mode == "full":
        await run_full_pipeline(args.duration, args.silence, args.loop)

    elif args.mode == "text":
        await run_text_mode(args.loop)

    elif args.mode == "stt":
        await run_stt_mode(args.duration, args.silence, args.loop)

    print_header("TEST TERMINÃ‰")


if __name__ == "__main__":
    asyncio.run(main())
